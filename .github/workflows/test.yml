name: Test All Phases

on:
  repository_dispatch:
    types: [laminardb-updated]
  workflow_dispatch:
  push:
    branches: [master]

env:
  CARGO_TERM_COLOR: always
  LAMINAR_PG_HOST: localhost
  LAMINAR_PG_USER: laminar
  LAMINAR_PG_PASSWORD: laminar

jobs:
  test:
    name: Build & Test All Phases
    runs-on: ubuntu-latest
    timeout-minutes: 60

    steps:
      # â”€â”€ Checkout â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
      - name: Checkout laminardb-test
        uses: actions/checkout@v4

      - name: Clone laminardb (sibling directory for path deps)
        run: git clone --depth 1 https://github.com/laminardb/laminardb.git ../laminardb

      # â”€â”€ Setup â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
      - name: Install Rust stable
        uses: dtolnay/rust-toolchain@stable

      - name: Get laminardb commit hash (for cache key)
        id: laminardb-hash
        run: echo "hash=$(git -C ../laminardb rev-parse --short HEAD)" >> $GITHUB_OUTPUT

      - name: Cache Rust build artifacts
        uses: Swatinem/rust-cache@v2
        with:
          shared-key: "laminardb-${{ steps.laminardb-hash.outputs.hash }}"
          cache-on-failure: true

      - name: Install system dependencies
        run: sudo apt-get update && sudo apt-get install -y cmake postgresql-client libcurl4-openssl-dev pkg-config libssl-dev

      # â”€â”€ Services â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
      - name: Start Postgres
        run: |
          docker run -d --name postgres \
            -p 5432:5432 \
            -e POSTGRES_DB=shop \
            -e POSTGRES_USER=laminar \
            -e POSTGRES_PASSWORD=laminar \
            -v ${{ github.workspace }}/sql/init-cdc.sql:/docker-entrypoint-initdb.d/01-init.sql \
            postgres:16 \
            postgres -c wal_level=logical -c max_replication_slots=4 -c max_wal_senders=4

      - name: Pull Redpanda image
        run: docker pull redpandadata/redpanda:v24.1.21

      - name: Start Redpanda
        run: |
          docker run -d --name redpanda \
            -p 19092:19092 -p 18082:18082 -p 9644:9644 \
            redpandadata/redpanda:v24.1.21 \
            redpanda start \
            --smp=1 --memory=512M --overprovisioned \
            --kafka-addr internal://0.0.0.0:9092,external://0.0.0.0:19092 \
            --advertise-kafka-addr internal://redpanda:9092,external://localhost:19092 \
            --pandaproxy-addr internal://0.0.0.0:8082,external://0.0.0.0:18082 \
            --advertise-pandaproxy-addr internal://redpanda:8082,external://localhost:18082 \
            --mode dev-container

      - name: Wait for Postgres
        run: |
          for i in $(seq 1 30); do
            if pg_isready -h localhost -U laminar -d shop 2>/dev/null; then
              echo "Postgres is ready"
              break
            fi
            echo "Waiting for Postgres... ($i/30)"
            sleep 2
          done

      - name: Wait for Redpanda
        run: |
          for i in $(seq 1 30); do
            if docker exec redpanda rpk cluster health 2>/dev/null | grep -q "HEALTHY"; then
              echo "Redpanda is healthy"
              break
            fi
            echo "Waiting for Redpanda... ($i/30)"
            sleep 2
          done

      # â”€â”€ Build â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
      - name: Build (release)
        run: cargo build --release

      # â”€â”€ Run Phases â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
      - name: "Phase 1: Rust API"
        id: phase1
        timeout-minutes: 2
        run: |
          set +e
          OUTPUT=$(cargo run --release -- phase1 2>&1)
          EXIT_CODE=$?
          echo "$OUTPUT"
          echo "output<<EOF" >> $GITHUB_OUTPUT
          echo "$OUTPUT" >> $GITHUB_OUTPUT
          echo "EOF" >> $GITHUB_OUTPUT
          echo "exit_code=$EXIT_CODE" >> $GITHUB_OUTPUT
          exit 0

      - name: "Phase 2: Streaming SQL"
        id: phase2
        timeout-minutes: 2
        run: |
          set +e
          OUTPUT=$(cargo run --release -- phase2 2>&1)
          EXIT_CODE=$?
          echo "$OUTPUT"
          echo "output<<EOF" >> $GITHUB_OUTPUT
          echo "$OUTPUT" >> $GITHUB_OUTPUT
          echo "EOF" >> $GITHUB_OUTPUT
          echo "exit_code=$EXIT_CODE" >> $GITHUB_OUTPUT
          exit 0

      - name: "Phase 3: Kafka Pipeline"
        id: phase3
        timeout-minutes: 2
        run: |
          set +e
          OUTPUT=$(cargo run --release -- phase3 2>&1)
          EXIT_CODE=$?
          echo "$OUTPUT"
          echo "output<<EOF" >> $GITHUB_OUTPUT
          echo "$OUTPUT" >> $GITHUB_OUTPUT
          echo "EOF" >> $GITHUB_OUTPUT
          echo "exit_code=$EXIT_CODE" >> $GITHUB_OUTPUT
          exit 0

      - name: "Phase 4: Stream Joins"
        id: phase4
        timeout-minutes: 2
        run: |
          set +e
          OUTPUT=$(cargo run --release -- phase4 2>&1)
          EXIT_CODE=$?
          echo "$OUTPUT"
          echo "output<<EOF" >> $GITHUB_OUTPUT
          echo "$OUTPUT" >> $GITHUB_OUTPUT
          echo "EOF" >> $GITHUB_OUTPUT
          echo "exit_code=$EXIT_CODE" >> $GITHUB_OUTPUT
          exit 0

      - name: "Phase 5: CDC Pipeline"
        id: phase5
        timeout-minutes: 2
        run: |
          set +e
          OUTPUT=$(cargo run --release -- phase5 2>&1)
          EXIT_CODE=$?
          echo "$OUTPUT"
          echo "output<<EOF" >> $GITHUB_OUTPUT
          echo "$OUTPUT" >> $GITHUB_OUTPUT
          echo "EOF" >> $GITHUB_OUTPUT
          echo "exit_code=$EXIT_CODE" >> $GITHUB_OUTPUT
          exit 0

      - name: "Phase 6: Bonus (HOP, SESSION, EMIT ON UPDATE)"
        id: phase6
        timeout-minutes: 2
        run: |
          set +e
          OUTPUT=$(cargo run --release -- phase6 2>&1)
          EXIT_CODE=$?
          echo "$OUTPUT"
          echo "output<<EOF" >> $GITHUB_OUTPUT
          echo "$OUTPUT" >> $GITHUB_OUTPUT
          echo "EOF" >> $GITHUB_OUTPUT
          echo "exit_code=$EXIT_CODE" >> $GITHUB_OUTPUT
          exit 0

      - name: "Phase 8: v0.12.0 Feature Tests"
        id: phase8
        timeout-minutes: 5
        run: |
          set +e
          OUTPUT=$(cargo run -- phase8 2>&1)
          EXIT_CODE=$?
          echo "$OUTPUT"
          echo "output<<EOF" >> $GITHUB_OUTPUT
          echo "$OUTPUT" >> $GITHUB_OUTPUT
          echo "EOF" >> $GITHUB_OUTPUT
          echo "exit_code=$EXIT_CODE" >> $GITHUB_OUTPUT
          exit 0

      - name: "Phase 9: API Surface Tests"
        id: phase9
        timeout-minutes: 5
        run: |
          set +e
          OUTPUT=$(cargo run -- phase9 2>&1)
          EXIT_CODE=$?
          echo "$OUTPUT"
          echo "output<<EOF" >> $GITHUB_OUTPUT
          echo "$OUTPUT" >> $GITHUB_OUTPUT
          echo "EOF" >> $GITHUB_OUTPUT
          echo "exit_code=$EXIT_CODE" >> $GITHUB_OUTPUT
          exit 0

      - name: "Phase 7: Stress Test (6-stream fraud-detect pipeline)"
        id: phase7
        timeout-minutes: 10
        run: |
          STRESS_DURATION=10 cargo run --release -- phase7 2>&1 | tee stress_output.txt
          echo "output<<EOF" >> $GITHUB_OUTPUT
          cat stress_output.txt >> $GITHUB_OUTPUT
          echo "EOF" >> $GITHUB_OUTPUT

      - name: Stress test summary
        if: always()
        run: |
          echo "## Stress Test Results (Phase 7)" >> $GITHUB_STEP_SUMMARY
          echo '```' >> $GITHUB_STEP_SUMMARY
          # Only include the results table and summary (last 30 lines) to stay under step summary size limit
          tail -30 stress_output.txt >> $GITHUB_STEP_SUMMARY 2>/dev/null || echo "(no output)" >> $GITHUB_STEP_SUMMARY
          echo '```' >> $GITHUB_STEP_SUMMARY

      # â”€â”€ Criterion Benchmarks â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
      - name: "Benchmark: Criterion throughput"
        id: bench
        timeout-minutes: 30
        run: |
          cargo bench 2>&1 | tee bench_output.txt
          echo "output<<EOF" >> $GITHUB_OUTPUT
          cat bench_output.txt >> $GITHUB_OUTPUT
          echo "EOF" >> $GITHUB_OUTPUT

      - name: Benchmark summary
        if: always()
        run: |
          echo "## Criterion Benchmarks" >> $GITHUB_STEP_SUMMARY
          echo '```' >> $GITHUB_STEP_SUMMARY
          # Only include benchmark result lines to stay under step summary size limit
          grep -E '(^Benchmarking|^pipeline_setup|^push_throughput|^end_to_end|time:)' bench_output.txt >> $GITHUB_STEP_SUMMARY 2>/dev/null || echo "(no output)" >> $GITHUB_STEP_SUMMARY
          echo '```' >> $GITHUB_STEP_SUMMARY

      # â”€â”€ Results Summary â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
      - name: Generate Job Summary
        if: always()
        env:
          P1_OUT: ${{ steps.phase1.outputs.output }}
          P2_OUT: ${{ steps.phase2.outputs.output }}
          P3_OUT: ${{ steps.phase3.outputs.output }}
          P4_OUT: ${{ steps.phase4.outputs.output }}
          P5_OUT: ${{ steps.phase5.outputs.output }}
          P6_OUT: ${{ steps.phase6.outputs.output }}
          P7_OUT: ${{ steps.phase7.outputs.output }}
          P8_OUT: ${{ steps.phase8.outputs.output }}
          P9_OUT: ${{ steps.phase9.outputs.output }}
          BENCH_OUT: ${{ steps.bench.outputs.output }}
        run: |
          extract_status() {
            local output="$1"
            if echo "$output" | grep -q "PASS"; then
              if echo "$output" | grep -q "FAIL\|SKIP"; then
                echo "PARTIAL"
              else
                echo "PASS"
              fi
            elif echo "$output" | grep -q "FAIL"; then
              echo "FAIL"
            else
              echo "UNKNOWN"
            fi
          }

          P1_STATUS=$(extract_status "$P1_OUT")
          P2_STATUS=$(extract_status "$P2_OUT")
          P3_STATUS=$(extract_status "$P3_OUT")
          P4_STATUS=$(extract_status "$P4_OUT")
          P5_STATUS=$(extract_status "$P5_OUT")
          P6_STATUS=$(extract_status "$P6_OUT")
          P7_STATUS=$(extract_status "$P7_OUT")
          P8_STATUS=$(extract_status "$P8_OUT")
          P9_STATUS=$(extract_status "$P9_OUT")

          STATUS_EMOJI() {
            case "$1" in
              PASS) echo "âœ…" ;;
              PARTIAL) echo "ðŸŸ¡" ;;
              FAIL) echo "âŒ" ;;
              *) echo "â“" ;;
            esac
          }

          cat >> $GITHUB_STEP_SUMMARY << 'HEADER'
          ## laminardb-test Results

          | Phase | Description | Status | Details |
          |-------|-------------|--------|---------|
          HEADER

          echo "| 1 | Rust API | $(STATUS_EMOJI $P1_STATUS) $P1_STATUS | builder, execute, source, subscribe, push_batch, watermark, poll |" >> $GITHUB_STEP_SUMMARY
          echo "| 2 | Streaming SQL | $(STATUS_EMOJI $P2_STATUS) $P2_STATUS | tumble, first_value/last_value, cascading MVs |" >> $GITHUB_STEP_SUMMARY
          echo "| 3 | Kafka Pipeline | $(STATUS_EMOJI $P3_STATUS) $P3_STATUS | FROM KAFKA, INTO KAFKA, \${VAR} substitution |" >> $GITHUB_STEP_SUMMARY
          echo "| 4 | Stream Joins | $(STATUS_EMOJI $P4_STATUS) $P4_STATUS | ASOF JOIN, stream-stream INNER JOIN |" >> $GITHUB_STEP_SUMMARY
          echo "| 5 | CDC Pipeline | $(STATUS_EMOJI $P5_STATUS) $P5_STATUS | FROM postgres-cdc, _op filter, aggregation |" >> $GITHUB_STEP_SUMMARY
          echo "| 6+ | Bonus | $(STATUS_EMOJI $P6_STATUS) $P6_STATUS | HOP window, SESSION window, EMIT ON UPDATE |" >> $GITHUB_STEP_SUMMARY
          echo "| 7 | Stress Test | $(STATUS_EMOJI $P7_STATUS) $P7_STATUS | 6-stream fraud-detect pipeline, 7-level ramp, throughput benchmark |" >> $GITHUB_STEP_SUMMARY
          echo "| 8 | v0.12.0 Features | $(STATUS_EMOJI $P8_STATUS) $P8_STATUS | Cascading MVs #35, SESSION fix #55, EMIT ON WINDOW CLOSE #52, INTERVAL #69, late data #65 |" >> $GITHUB_STEP_SUMMARY
          echo "| 9 | API Surface | $(STATUS_EMOJI $P9_STATUS) $P9_STATUS | api::Connection #49, push_arrow #64, SourceHandle metadata, topology, metrics |" >> $GITHUB_STEP_SUMMARY

          echo "" >> $GITHUB_STEP_SUMMARY
          echo "### Phase Output" >> $GITHUB_STEP_SUMMARY

          # Truncate phase outputs to last 30 lines each to stay under 1024k step summary limit
          for PHASE in 1 2 3 4 5 6 8 9; do
            echo "" >> $GITHUB_STEP_SUMMARY
            echo "<details>" >> $GITHUB_STEP_SUMMARY
            echo "<summary>Phase ${PHASE} output (last 30 lines)</summary>" >> $GITHUB_STEP_SUMMARY
            echo "" >> $GITHUB_STEP_SUMMARY
            echo '```' >> $GITHUB_STEP_SUMMARY
            case $PHASE in
              1) echo "$P1_OUT" | tail -30 >> $GITHUB_STEP_SUMMARY ;;
              2) echo "$P2_OUT" | tail -30 >> $GITHUB_STEP_SUMMARY ;;
              3) echo "$P3_OUT" | tail -30 >> $GITHUB_STEP_SUMMARY ;;
              4) echo "$P4_OUT" | tail -30 >> $GITHUB_STEP_SUMMARY ;;
              5) echo "$P5_OUT" | tail -30 >> $GITHUB_STEP_SUMMARY ;;
              6) echo "$P6_OUT" | tail -30 >> $GITHUB_STEP_SUMMARY ;;
              8) echo "$P8_OUT" | tail -30 >> $GITHUB_STEP_SUMMARY ;;
              9) echo "$P9_OUT" | tail -30 >> $GITHUB_STEP_SUMMARY ;;
            esac
            echo '```' >> $GITHUB_STEP_SUMMARY
            echo "</details>" >> $GITHUB_STEP_SUMMARY
          done

      # â”€â”€ Issue Regression Detection â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
      - name: Check known issues
        if: always()
        env:
          P2_OUTPUT: ${{ steps.phase2.outputs.output }}
          P4_OUTPUT: ${{ steps.phase4.outputs.output }}
          P7_OUTPUT: ${{ steps.phase7.outputs.output }}
        run: |
          echo "### Issue Tracker" >> $GITHUB_STEP_SUMMARY
          echo "" >> $GITHUB_STEP_SUMMARY

          CASCADE_BARS=$(echo "$P2_OUTPUT" | grep -oP 'Level 2 \(cascade\) bars:\s+\K\d+' || echo "0")
          if [ "$CASCADE_BARS" -gt 0 ] 2>/dev/null; then
            echo "laminardb#35 (Cascading MVs): FIXED â€” $CASCADE_BARS bars produced"
            echo "- **laminardb#35** Cascading MVs: FIXED ($CASCADE_BARS bars)" >> $GITHUB_STEP_SUMMARY
          else
            echo "laminardb#35 (Cascading MVs): still failing (cascade_bars=$CASCADE_BARS)"
            echo "- **laminardb#35** Cascading MVs: not producing output" >> $GITHUB_STEP_SUMMARY
          fi

          ASOF_RESULTS=$(echo "$P4_OUTPUT" | grep -oP 'ASOF results:\s+\K\d+' || echo "0")
          if [ "$ASOF_RESULTS" -gt 0 ] 2>/dev/null; then
            echo "laminardb#37 (ASOF JOIN): FIXED â€” $ASOF_RESULTS results"
            echo "- **laminardb#37** ASOF JOIN: FIXED ($ASOF_RESULTS results)" >> $GITHUB_STEP_SUMMARY
          else
            echo "laminardb#37 (ASOF JOIN): still failing (asof_results=$ASOF_RESULTS)"
            echo "- **laminardb#37** ASOF JOIN: not producing output" >> $GITHUB_STEP_SUMMARY
          fi

          # Phase 7: Extract peak throughput and ASOF JOIN status
          PEAK_TPS=$(echo "$P7_OUTPUT" | grep -oP 'Peak sustained throughput: ~\K\d+' || echo "0")
          ASOF_P7=$(echo "$P7_OUTPUT" | grep -oP 'asof_match\s+\K\d+' || echo "0")
          echo "" >> $GITHUB_STEP_SUMMARY
          echo "### Stress Test (Phase 7)" >> $GITHUB_STEP_SUMMARY
          echo "- Peak throughput: ~${PEAK_TPS} trades/sec (baseline: ~2,275/sec)" >> $GITHUB_STEP_SUMMARY
          if [ "$ASOF_P7" -gt 0 ] 2>/dev/null; then
            echo "- **laminardb#57** ASOF JOIN in stress pipeline: FIXED ($ASOF_P7 output rows)" >> $GITHUB_STEP_SUMMARY
          else
            echo "- **laminardb#57** ASOF JOIN in stress pipeline: 0 output (same as published crate)" >> $GITHUB_STEP_SUMMARY
          fi

      # â”€â”€ Cleanup â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
      - name: Stop containers
        if: always()
        run: |
          docker stop redpanda postgres 2>/dev/null || true
          docker rm redpanda postgres 2>/dev/null || true
